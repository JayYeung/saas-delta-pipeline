{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from google.cloud import videointelligence\n",
    "\n",
    "def video_detect_text(path):\n",
    "    \"\"\"Detect text in a local video.\"\"\"\n",
    "    video_client = videointelligence.VideoIntelligenceServiceClient()\n",
    "    features = [videointelligence.Feature.TEXT_DETECTION]\n",
    "    video_context = videointelligence.VideoContext()\n",
    "\n",
    "    with io.open(path, \"rb\") as file:\n",
    "        input_content = file.read()\n",
    "\n",
    "    operation = video_client.annotate_video(\n",
    "        request={\n",
    "            \"features\": features,\n",
    "            \"input_content\": input_content,\n",
    "            \"video_context\": video_context,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(\"\\nProcessing video for text detection.\")\n",
    "    result = operation.result(timeout=1200)\n",
    "\n",
    "    # The first result is retrieved because a single video was processed.\n",
    "    annotation_result = result.annotation_results[0]\n",
    "\n",
    "    for text_annotation in annotation_result.text_annotations:\n",
    "        print(\"\\nText: {}\".format(text_annotation.text))\n",
    "\n",
    "        # Get the first text segment\n",
    "        text_segment = text_annotation.segments[0]\n",
    "        start_time = text_segment.segment.start_time_offset\n",
    "        end_time = text_segment.segment.end_time_offset\n",
    "        print(\n",
    "            \"start_time: {}, end_time: {}\".format(\n",
    "                start_time.seconds + start_time.microseconds * 1e-6,\n",
    "                end_time.seconds + end_time.microseconds * 1e-6,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        print(\"Confidence: {}\".format(text_segment.confidence))\n",
    "\n",
    "        # Show the result for the first frame in this segment.\n",
    "        frame = text_segment.frames[0]\n",
    "        time_offset = frame.time_offset\n",
    "        print(\n",
    "            \"Time offset for the first frame: {}\".format(\n",
    "                time_offset.seconds + time_offset.microseconds * 1e-6\n",
    "            )\n",
    "        )\n",
    "        print(\"Rotated Bounding Box Vertices:\")\n",
    "        for vertex in frame.rotated_bounding_box.vertices:\n",
    "            print(\"\\tVertex.x: {}, Vertex.y: {}\".format(vertex.x, vertex.y))\n",
    "            \n",
    "    return annotation_result\n",
    "\n",
    "annotation_result = video_detect_text('resources/meet_deadlines.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = ' '.join([text_annotation.text for text_annotation in annotation_result.text_annotations])\n",
    "print(input_text)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
