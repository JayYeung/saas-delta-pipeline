{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Skill': {0: 'Ability To Meet Deadlines',\n",
       "  1: 'Acceptance Testing',\n",
       "  2: 'Account Management',\n",
       "  3: 'Accounting Systems',\n",
       "  4: 'Accounts Payable / Receivable'},\n",
       " 'Skill Definition': {0: 'Capacity to complete a project or task by a predetermined date and time.',\n",
       "  1: 'Uses an engineering quality assurance process to measure how closely a particular output meets the specified requirements by way of feedback from end users.',\n",
       "  2: 'Account management is the practice of developing and maintaining relationships with individual clients to retain, grow, and/or land new business.',\n",
       "  3: 'Accounting Systems is a computer application that records and processes accounting transactions per business requirements.',\n",
       "  4: 'Accounts Payable refers to knowledge of bookkeeping methods to tracking payments a company owes to its suppliers in order to approve and process invoices. Accounts receivable are claims for payment held by a business for goods or services that have been ordered but remain unpaid.'},\n",
       " 'Skill Type': {0: 'Behavioral',\n",
       "  1: 'Technical',\n",
       "  2: 'Technical',\n",
       "  3: 'Technical',\n",
       "  4: 'Technical'}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "skill_def = pd.read_csv('resources/skill_definitions.csv')\n",
    "skill_def.head().to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First approach using huggingface classifier (bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "\n",
    "# input_text = \"\"\"\n",
    "# The image sequence appears to be a presentation slide or series of slides related to the Federal Aviation Administration (FAA), prominently featuring the FAA logo—a globe with a winged emblem and the text \"Federal Aviation Administration\" encircling it. The slides vary slightly in design, with some including airplane icons and a text bar reading \"This is the FAA.\" The background is a gradient of blue shades. The slides emphasize the FAA\\'s role in aviation, displaying statistics such as 5,000 flights in the air at any given time and 44,000 flights each day, with 2.6 million passengers traveling daily and 9.7 million scheduled passenger flights annually. Key organizations highlighted include the Air Traffic Organization (ATO), Office of Airports (ARP), Aviation Safety (AVS), Security and Hazardous Materials (ASH), and Commercial Space Transportation (AST), underscoring the complexity and scale of air travel management and safety.\n",
    "# \"\"\"\n",
    "\n",
    "# # Load a pre-trained zero-shot classification model\n",
    "# classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# # Define your classification labels and their desciptions\n",
    "# labels = skill_def['Skill'] + ' (' + skill_def['Skill Type'] + ')'\n",
    "\n",
    "# # Perform zero-shot classification\n",
    "# result = classifier(input_text, candidate_labels=labels)\n",
    "\n",
    "# # Display the results\n",
    "# print(\"Input Text:\", input_text)\n",
    "# print(\"Predicted Labels with Scores:\")\n",
    "# for label, score in zip(result[\"labels\"], result[\"scores\"]):\n",
    "#     print(f\"{label}: {score:.4f}\")\n",
    "\n",
    "# # Optional: Save results to a DataFrame for further analysis\n",
    "# results_df = pd.DataFrame({\n",
    "#     \"Label\": result[\"labels\"],\n",
    "#     \"Score\": result[\"scores\"]\n",
    "# }).sort_values(by='Score', ascending=False)\n",
    "# print(\"\\nResults DataFrame:\")\n",
    "# print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up reading metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_confidence.logprobs_handler import LogprobsHandler\n",
    "logprobs_handler = LogprobsHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3865814531.py, line 37)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 37\u001b[0;36m\u001b[0m\n\u001b[0;31m    )\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import json, time\n",
    "\n",
    "class TextLabeler:\n",
    "    def __init__(self, data_path: str, skill_def: pd.DataFrame, client: OpenAI, model: str, max_retries: int = 3, delay: float = 1.0, output_path:str=\"resources/results.json\"):\n",
    "        self.data_path = data_path\n",
    "        with open(data_path, 'r') as file:\n",
    "            self.data = json.load(file)\n",
    "        self.skill_def = skill_def\n",
    "        self.client = client\n",
    "        self.model = model\n",
    "        self.max_retries = max_retries\n",
    "        self.delay = delay\n",
    "        self.output_path = output_path\n",
    "\n",
    "    def _build_user_prompt_content(self, entry: dict):\n",
    "        return '\\n'.join([f\"{key}: {entry[key]}\" for key in ['title', 'description', 'summary']])\n",
    "    \n",
    "    def _build_system_prompt_content(self):\n",
    "        return f\"\"\"You are in the context of labeling a Delta airline training video.\n",
    "        You are labeling the given title/description/summary, picking the most appropriate labels that perfectly fit \\\n",
    "        everything out of THE ONLY FOLLOWING OPTIONS FOR LABELS: \\\n",
    "        {'; '.join('(id: ' + self.skill_def.index.astype(str) + ', label: ' + self.skill_def['Skill'] + ')')}.\\\n",
    "        Your output should be in descending order of the best labels that fit the title/description/summary STRICTLY following this output structure \\\n",
    "        structure with NO EXTRA CONTENT (should be only around 3-5 labels): \\\"Labels: <id of first label>, <id of second label>, ..., <id of last label>\\\"\"\"\"\n",
    "    \n",
    "    def build_labels(self, entry: dict):\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self._build_system_prompt_content()},\n",
    "                {\"role\": \"user\", \"content\": self._build_user_prompt_content(entry)},\n",
    "            ],\n",
    "            stream=False,\n",
    "            logprobs=True,\n",
    "            top_logprobs=\n",
    "        )\n",
    "        \n",
    "        print(response.choices[0].message.content)\n",
    "\n",
    "        # Logprobs\n",
    "        print(response.choices[0])\n",
    "        response_logprobs = response.choices[0].logprobs.content# if hasattr(response.choices[0], 'logprobs') else []\n",
    "        logprobs_formatted = logprobs_handler.format_logprobs(response_logprobs)\n",
    "        confidence = logprobs_handler.process_logprobs(logprobs_formatted)\n",
    "        print(confidence)\n",
    "\n",
    "        label_ids = response.choices[0].message.content[len('Labels: '):].split(', ')\n",
    "        filtered_skills_df = self.skill_def.iloc[[int(id) for id in label_ids]]\n",
    "        return filtered_skills_df['Skill'].to_list()\n",
    "    \n",
    "    def revise_metadata_labels(self):\n",
    "        for entry in self.data['data']:\n",
    "            print(f\"Generating labels for {entry['title']}...\")\n",
    "            for attempt in range(self.max_retries):\n",
    "                try:\n",
    "                    new_labels = self.build_labels(entry)\n",
    "                except:\n",
    "                    print(\"An error has occured.\")\n",
    "                    if attempt == self.max_retries - 1:\n",
    "                        raise\n",
    "                    time.sleep(self.delay * (attempt + 1))\n",
    "                else:\n",
    "                    break\n",
    "            entry['labels'] = new_labels\n",
    "            \n",
    "            # For saving progress\n",
    "            with open(self.output_path, 'w') as file:\n",
    "                json.dump(self.data, file, indent=4)\n",
    "            print(f\"Added labels for {entry['title']}\")\n",
    "        print('Added all entry labels successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second approach using deepseek chat (much better results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating labels for Fingerprint Technician - Fingerprint Capture Training...\n",
      "Labels: 17, 158, 224, 265, 360\n",
      "Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='Labels', bytes=[76, 97, 98, 101, 108, 115], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=':', bytes=[58], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='17', bytes=[49, 55], logprob=-0.00013543092, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='158', bytes=[49, 53, 56], logprob=-0.026875073, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='224', bytes=[50, 50, 52], logprob=-0.0039386726, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-0.002706312, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='265', bytes=[50, 54, 53], logprob=-0.37962317, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-0.001702983, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='360', bytes=[51, 54, 48], logprob=-0.12672183, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='Labels: 17, 158, 224, 265, 360', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))\n",
      "{}\n",
      "Added labels for Fingerprint Technician - Fingerprint Capture Training\n",
      "Generating labels for CCT - Privacy and Data Protection...\n",
      "Labels: 93, 97, 265, 272, 339\n",
      "Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='Labels', bytes=[76, 97, 98, 101, 108, 115], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=':', bytes=[58], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='93', bytes=[57, 51], logprob=-0.26260224, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='97', bytes=[57, 55], logprob=-0.7200994, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='265', bytes=[50, 54, 53], logprob=-1.8130658, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='272', bytes=[50, 55, 50], logprob=-0.51050943, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-1.3113031e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='339', bytes=[51, 51, 57], logprob=-1.6719563, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='Labels: 93, 97, 265, 272, 339', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))\n",
      "{}\n",
      "Added labels for CCT - Privacy and Data Protection\n",
      "Generating labels for Fire Extinguisher Safety...\n",
      "Labels: 360, 277, 117, 65, 275\n",
      "Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='Labels', bytes=[76, 97, 98, 101, 108, 115], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=':', bytes=[58], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='360', bytes=[51, 54, 48], logprob=-0.074271955, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='277', bytes=[50, 55, 55], logprob=-0.025839934, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='117', bytes=[49, 49, 55], logprob=-0.0013538819, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-0.014002327, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='65', bytes=[54, 53], logprob=-0.6182739, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-0.0031312802, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='275', bytes=[50, 55, 53], logprob=-0.6962436, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='Labels: 360, 277, 117, 65, 275', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))\n",
      "{}\n",
      "Added labels for Fire Extinguisher Safety\n",
      "Generating labels for Delta Incident Reporting training course video capture (NO AUDIO)...\n",
      "Labels: 174, 275, 360, 117, 272\n",
      "Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='Labels', bytes=[76, 97, 98, 101, 108, 115], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=':', bytes=[58], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='174', bytes=[49, 55, 52], logprob=-0.069498524, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='275', bytes=[50, 55, 53], logprob=-0.008736155, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='360', bytes=[51, 54, 48], logprob=-0.04894939, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='117', bytes=[49, 49, 55], logprob=-0.19105662, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='272', bytes=[50, 55, 50], logprob=-3.2705326, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='Labels: 174, 275, 360, 117, 272', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))\n",
      "{}\n",
      "Added labels for Delta Incident Reporting training course video capture (NO AUDIO)\n",
      "Generating labels for Corporate Safety - Incident Investigation...\n",
      "Labels: 174, 275, 274, 360, 117\n",
      "Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='Labels', bytes=[76, 97, 98, 101, 108, 115], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=':', bytes=[58], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='174', bytes=[49, 55, 52], logprob=-0.007846241, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='275', bytes=[50, 55, 53], logprob=-0.014824477, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='274', bytes=[50, 55, 52], logprob=-0.60803413, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='360', bytes=[51, 54, 48], logprob=-0.0063331574, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='117', bytes=[49, 49, 55], logprob=-0.14710492, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='Labels: 174, 275, 274, 360, 117', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))\n",
      "{}\n",
      "Added labels for Corporate Safety - Incident Investigation\n",
      "Generating labels for Interview Skills For Hiring Managers...\n",
      "Labels: 319, 262, 263, 181, 182\n",
      "Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='Labels', bytes=[76, 97, 98, 101, 108, 115], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=':', bytes=[58], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='319', bytes=[51, 49, 57], logprob=-3.9339143e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='262', bytes=[50, 54, 50], logprob=-0.040966567, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='263', bytes=[50, 54, 51], logprob=-8.583106e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-6.866691e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='181', bytes=[49, 56, 49], logprob=-0.10515281, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-2.384186e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='182', bytes=[49, 56, 50], logprob=-0.002476478, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='Labels: 319, 262, 263, 181, 182', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))\n",
      "{}\n",
      "Added labels for Interview Skills For Hiring Managers\n",
      "Generating labels for Information Security Awareness - Standard (Recurrent)...\n",
      "Labels: 91, 90, 161, 207, 56\n",
      "Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='Labels', bytes=[76, 97, 98, 101, 108, 115], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=':', bytes=[58], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='91', bytes=[57, 49], logprob=-0.056332536, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='90', bytes=[57, 48], logprob=-0.00030736878, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='161', bytes=[49, 54, 49], logprob=-1.1749218, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='207', bytes=[50, 48, 55], logprob=-0.073897354, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='56', bytes=[53, 54], logprob=-0.006585659, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='Labels: 91, 90, 161, 207, 56', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))\n",
      "{}\n",
      "Added labels for Information Security Awareness - Standard (Recurrent)\n",
      "Added all entry labels successfully.\n"
     ]
    }
   ],
   "source": [
    "deep_seek_client = OpenAI(api_key=\"sk-REDACTED\", base_url=\"https://api.deepseek.com\")\n",
    "deep_seek_tl = TextLabeler('resources/bedrock_demo.json', skill_def, deep_seek_client, 'deepseek-chat')\n",
    "deep_seek_tl.revise_metadata_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third approach using gpt 4o mini (slightly worse results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating labels for Fingerprint Technician - Fingerprint Capture Training...\n",
      "Labels: 17, 18, 340, 40, 7\n",
      "Added labels for Fingerprint Technician - Fingerprint Capture Training\n",
      "Generating labels for CCT - Privacy and Data Protection...\n",
      "Labels: 265, 340, 370, 374, 219\n",
      "An error has occured.\n",
      "Labels: 65, 268, 272, 216, 280\n",
      "Added labels for CCT - Privacy and Data Protection\n",
      "Generating labels for Fire Extinguisher Safety...\n",
      "Labels: 117, 275, 277, 340\n",
      "Added labels for Fire Extinguisher Safety\n",
      "Generating labels for Delta Incident Reporting training course video capture (NO AUDIO)...\n",
      "Labels: 30, 275, 278, 340, 336\n",
      "Added labels for Delta Incident Reporting training course video capture (NO AUDIO)\n",
      "Generating labels for Corporate Safety - Incident Investigation...\n",
      "Labels: 30, 275, 277, 72, 65\n",
      "Added labels for Corporate Safety - Incident Investigation\n",
      "Generating labels for Interview Skills For Hiring Managers...\n",
      "Labels: 9, 340, 37, 40, 221\n",
      "Added labels for Interview Skills For Hiring Managers\n",
      "Generating labels for Information Security Awareness - Standard (Recurrent)...\n",
      "Labels: 65, 111, 340, 30\n",
      "Added labels for Information Security Awareness - Standard (Recurrent)\n",
      "Added all entry labels successfully.\n"
     ]
    }
   ],
   "source": [
    "gpt_4o_mini_client = OpenAI(api_key=\"sk-REDACTED\")\n",
    "gpt_4o_mini_tl = TextLabeler('resources/bedrock_demo.json', skill_def, gpt_4o_mini_client, 'gpt-4o-mini')\n",
    "gpt_4o_mini_tl.revise_metadata_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourth approach using gpt 4.1 (about the same as deepseek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating labels for Fingerprint Technician - Fingerprint Capture Training...\n",
      "Labels: 340, 329, 17, 261\n",
      "Added labels for Fingerprint Technician - Fingerprint Capture Training\n",
      "Generating labels for CCT - Privacy and Data Protection...\n",
      "Labels: 265, 97, 340, 346, 277\n",
      "Added labels for CCT - Privacy and Data Protection\n",
      "Generating labels for Fire Extinguisher Safety...\n",
      "Labels: 277, 117, 360, 7\n",
      "Added labels for Fire Extinguisher Safety\n",
      "Generating labels for Delta Incident Reporting training course video capture (NO AUDIO)...\n",
      "Labels: 174, 360, 275, 277, 117\n",
      "Added labels for Delta Incident Reporting training course video capture (NO AUDIO)\n",
      "Generating labels for Corporate Safety - Incident Investigation...\n",
      "Labels: 174, 277, 275, 360, 230\n",
      "Added labels for Corporate Safety - Incident Investigation\n",
      "Generating labels for Interview Skills For Hiring Managers...\n",
      "Labels: 340, 9, 319, 181\n",
      "Added labels for Interview Skills For Hiring Managers\n",
      "Generating labels for Information Security Awareness - Standard (Recurrent)...\n",
      "Labels: 65, 90, 277, 158, 161\n",
      "Added labels for Information Security Awareness - Standard (Recurrent)\n",
      "Added all entry labels successfully.\n"
     ]
    }
   ],
   "source": [
    "gpt_4_client = OpenAI(api_key=\"sk-REDACTED\")\n",
    "gpt_4_tl = TextLabeler('resources/bedrock_demo.json', skill_def, gpt_4_client, 'gpt-4.1-2025-04-14')\n",
    "gpt_4_tl.revise_metadata_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"city\": \"Berlin\",\n",
      "  \"country\": \"Germany\"\n",
      "}\n",
      "{'city': 0.7698, 'country': 1.0}\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\",\n",
    "     \"content\": \"Return exactly one JSON object with keys city and country\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me a European capital\"}\n",
    "]\n",
    "\n",
    "resp = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    logprobs=True,\n",
    "    top_logprobs=2,\n",
    "    temperature=0,\n",
    "    response_format={\"type\": \"json_object\"},\n",
    ")\n",
    "\n",
    "tokens = resp.choices[0].logprobs.content        # list[ChatCompletionTokenLogprob]  :contentReference[oaicite:1]{index=1}\n",
    "logprobs_formatted = logprobs_handler.format_logprobs(tokens)\n",
    "\n",
    "confidence = logprobs_handler.process_logprobs(\n",
    "    logprobs_formatted,\n",
    "    # optional: nested_keys_dct=... if you want to aggregate sub‑fields\n",
    ")\n",
    "\n",
    "print(resp.choices[0].message.content)   # → {\"city\":\"Paris\",\"country\":\"France\"}\n",
    "print(confidence)                        # → {\"city\":0.97,\"country\":0.93}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "overall_p = math.exp(sum(t.logprob for t in tokens))\n",
    "# or average log‑prob for length‑independent metric:\n",
    "avg_lp = sum(t.logprob for t in tokens) / len(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USE THIS FOR LOGPROBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ Generating labels for: Fingerprint Technician - Fingerprint Capture Training\n",
      "✓ Added labels: ['Airport Security', 'Aviation Safety', 'Compliance Training', 'Training And Development']\n",
      "  confidences : {'label_1': 0.7914, 'label_2': 0.4579, 'label_3': 0.1365, 'label_4': 0.2716}\n",
      "\n",
      "▶ Generating labels for: CCT - Privacy and Data Protection\n",
      "✓ Added labels: ['Compliance Training', 'Risk Management', 'Training And Development', 'Understanding Customer Needs', 'Version Control']\n",
      "  confidences : {'label_1': 0.802, 'label_2': 0.3266, 'label_3': 0.1062, 'label_4': 0.098, 'label_5': 0.0803}\n",
      "\n",
      "▶ Generating labels for: Fire Extinguisher Safety\n",
      "✓ Added labels: ['Emergency Procedures', 'Safety Training', 'Workplace Safety']\n",
      "  confidences : {'label_1': 0.9218, 'label_2': 0.5571, 'label_3': 0.9881}\n",
      "\n",
      "▶ Generating labels for: Delta Incident Reporting training course video capture (NO AUDIO)\n",
      "✓ Added labels: ['Aviation Safety', 'Emergency Procedures', 'Safety Assurance', 'Risk Management', 'Training And Development']\n",
      "  confidences : {'label_1': 0.5401, 'label_2': 0.6754, 'label_3': 0.3177, 'label_4': 0.1121, 'label_5': 0.5172}\n",
      "\n",
      "▶ Generating labels for: Corporate Safety - Incident Investigation\n",
      "✓ Added labels: ['Aviation Safety', 'Safety Assurance', 'Safety Training', 'Training And Development']\n",
      "  confidences : {'label_1': 0.8477, 'label_2': 0.3098, 'label_3': 0.5177, 'label_4': 0.2297}\n",
      "\n",
      "▶ Generating labels for: Interview Skills For Hiring Managers\n",
      "✓ Added labels: ['Advising', 'Employee Engagement', 'Training And Development', 'Project Management']\n",
      "  confidences : {'label_1': 0.4374, 'label_2': 0.437, 'label_3': 0.7427, 'label_4': 0.1829}\n",
      "\n",
      "▶ Generating labels for: Information Security Awareness - Standard (Recurrent)\n",
      "✓ Added labels: ['Compliance Training', 'Risk Management', 'Training And Development']\n",
      "  confidences : {'label_1': 0.9965, 'label_2': 0.346, 'label_3': 0.6727}\n",
      "\n",
      "All entries processed successfully.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TextLabeler — Robust skill labeling tool for Delta Air Lines training content\n",
    "\n",
    "A production-grade tool that:\n",
    "- Automatically resets skill table indexes to 0-based integers for reliable ID lookup\n",
    "- Maintains a human-readable \"Skill\" column alongside machine-friendly IDs\n",
    "- Returns per-label confidence scores for each prediction\n",
    "- Handles API retries and incremental saving automatically\n",
    "\n",
    "Typical usage:\n",
    "1. Prepare skill definitions CSV with a \"Skill\" column\n",
    "2. Load input JSON containing training content metadata\n",
    "3. Process entries to generate and save labeled results\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import json, time\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from llm_confidence.logprobs_handler import LogprobsHandler\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------- helpers\n",
    "def _prepare_skill_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prepare skill definition dataframe for consistent processing.\n",
    "    \n",
    "    Args:\n",
    "        df: Raw skill definitions dataframe\n",
    "        \n",
    "    Returns:\n",
    "        Processed dataframe with:\n",
    "        - Cleaned column names (stripped whitespace)\n",
    "        - Guaranteed \"Skill\" column (renames first column if needed)\n",
    "        - Reset 0-based integer index (used as reference IDs)\n",
    "        \n",
    "    Note:\n",
    "        The reset index becomes the canonical ID system used throughout labeling\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df.columns = df.columns.str.strip()\n",
    "    if \"Skill\" not in df.columns:\n",
    "        df.rename(columns={df.columns[0]: \"Skill\"}, inplace=True)\n",
    "    return df.reset_index(drop=True)  # Ensure 0-based integer IDs\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------- main class\n",
    "class TextLabeler:\n",
    "    \"\"\"\n",
    "    Automated skill labeling system for training content metadata.\n",
    "    \n",
    "    Attributes:\n",
    "        client: OpenAI API client instance\n",
    "        model: Name of LLM model to use (e.g., \"gpt-4\")\n",
    "        max_retries: Maximum API call attempts before failing\n",
    "        delay: Base delay between retry attempts (seconds)\n",
    "        output_path: Path for incremental result saving\n",
    "        data: Loaded content metadata to process\n",
    "        skill_def: Processed skill definitions dataframe\n",
    "        log_handler: Confidence score calculator\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path: str,\n",
    "        skill_def: pd.DataFrame,\n",
    "        *,\n",
    "        client: OpenAI,\n",
    "        model: str,\n",
    "        max_retries: int = 3,\n",
    "        delay: float = 1.0,\n",
    "        output_path: str = \"resources/results.json\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the text labeler with configuration and data sources.\n",
    "        \n",
    "        Args:\n",
    "            data_path: Path to JSON file containing content metadata\n",
    "            skill_def: Dataframe of skill definitions (must contain \"Skill\" column)\n",
    "            client: Configured OpenAI client instance\n",
    "            model: LLM model identifier to use\n",
    "            max_retries: API call retry attempts (default: 3)\n",
    "            delay: Base delay between retries in seconds (default: 1.0)\n",
    "            output_path: Results output path (default: \"resources/results.json\")\n",
    "        \"\"\"\n",
    "        self.client = client\n",
    "        self.model = model\n",
    "        self.max_retries = max_retries\n",
    "        self.delay = delay\n",
    "        self.output_path = output_path\n",
    "\n",
    "        with open(data_path, \"r\") as f:\n",
    "            self.data = json.load(f)\n",
    "\n",
    "        self.skill_def = _prepare_skill_df(skill_def)\n",
    "        self.log_handler = LogprobsHandler()\n",
    "\n",
    "    # ---------------------------------------------------------------- prompt builders\n",
    "    def _build_user_prompt_content(self, entry: dict) -> str:\n",
    "        \"\"\"\n",
    "        Construct user prompt from content metadata entry.\n",
    "        \n",
    "        Args:\n",
    "            entry: Dictionary containing content metadata with keys:\n",
    "                   - title\n",
    "                   - description \n",
    "                   - summary\n",
    "                   \n",
    "        Returns:\n",
    "            Concatenated string of relevant content fields\n",
    "        \"\"\"\n",
    "        return \"\\n\".join(\n",
    "            f\"{k}: {entry[k]}\" for k in (\"title\", \"description\", \"summary\")\n",
    "        )\n",
    "\n",
    "    def _build_system_prompt_content(self) -> str:\n",
    "        \"\"\"\n",
    "        Construct the system prompt with skill labeling instructions.\n",
    "        \n",
    "        Returns:\n",
    "            Complete system prompt containing:\n",
    "            - Task description\n",
    "            - Required response format\n",
    "            - Complete skill list with IDs and names\n",
    "            - Example response\n",
    "        \"\"\"\n",
    "        label_list = \"; \".join(\n",
    "            f\"(id: {idx}, label: {name})\"\n",
    "            for idx, name in zip(self.skill_def.index, self.skill_def[\"Skill\"])\n",
    "        )\n",
    "        return (\n",
    "            \"You are an expert skill‑tagger for Delta Air Lines training videos.\\n\"\n",
    "            \"Select the 3‑5 best‑fitting labels from the list below and reply with \"\n",
    "            \"ONE JSON object whose keys are label_1, label_2, … and whose values \"\n",
    "            \"are the integer ids.  No commentary, no other keys.\\n\\n\"\n",
    "            f\"AVAILABLE LABELS: {label_list}\\n\\n\"\n",
    "            'EXAMPLE: {\"label_1\": 4, \"label_2\": 17, \"label_3\": 9}'\n",
    "        )\n",
    "\n",
    "    # ---------------------------------------------------------------- single call\n",
    "    def build_labels(self, entry: dict) -> tuple[list[str], dict[str, float]]:\n",
    "        \"\"\"\n",
    "        Generate skill labels for a single content entry.\n",
    "        \n",
    "        Args:\n",
    "            entry: Content metadata dictionary to label\n",
    "            \n",
    "        Returns:\n",
    "            Tuple containing:\n",
    "            - List of skill names (ordered by relevance)\n",
    "            - Dictionary of confidence scores per label key\n",
    "            \n",
    "        Raises:\n",
    "            OpenAI API exceptions after max retries exceeded\n",
    "        \"\"\"\n",
    "        resp = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self._build_system_prompt_content()},\n",
    "                {\"role\": \"user\", \"content\": self._build_user_prompt_content(entry)},\n",
    "            ],\n",
    "            logprobs=True,\n",
    "            top_logprobs=2,\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            temperature=0,\n",
    "            stream=False,\n",
    "        )\n",
    "\n",
    "        reply_json = json.loads(resp.choices[0].message.content.strip())\n",
    "        tokens = resp.choices[0].logprobs.content\n",
    "\n",
    "        # Calculate confidence scores for each label\n",
    "        logp_fmt = self.log_handler.format_logprobs(tokens)\n",
    "        confidences = self.log_handler.process_logprobs(logp_fmt)  # {'label_1': p1, ...}\n",
    "\n",
    "        # Convert numeric IDs to human-readable skill names\n",
    "        label_ids = [reply_json[k] for k in sorted(reply_json)]  # label_1, label_2, ...\n",
    "        skills = self.skill_def.loc[label_ids, \"Skill\"].tolist()\n",
    "\n",
    "        return skills, confidences\n",
    "\n",
    "    # ---------------------------------------------------------------- bulk driver\n",
    "    def revise_metadata_labels(self) -> None:\n",
    "        \"\"\"\n",
    "        Process all content entries to generate and save skill labels.\n",
    "        \n",
    "        Processes all entries in self.data['data'], adding:\n",
    "        - \"labels\": List of skill names\n",
    "        - \"confidences\": Per-label confidence scores\n",
    "        \n",
    "        Saves results incrementally to output_path.\n",
    "        \n",
    "        Note:\n",
    "            Implements retry logic with exponential backoff\n",
    "            Provides real-time console feedback\n",
    "            Maintains results through interruptions\n",
    "        \"\"\"\n",
    "        for entry in self.data[\"data\"]:\n",
    "            print(f\"\\n▶ Generating labels for: {entry['title']}\")\n",
    "            for attempt in range(self.max_retries):\n",
    "                try:\n",
    "                    labels, conf = self.build_labels(entry)\n",
    "                except Exception as e:\n",
    "                    print(\"Error:\", e)\n",
    "                    if attempt == self.max_retries - 1:\n",
    "                        raise\n",
    "                    time.sleep(self.delay * (attempt + 1))\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            entry[\"labels\"] = labels\n",
    "            entry[\"confidences\"] = conf\n",
    "\n",
    "            # Incremental save for crash recovery\n",
    "            with open(self.output_path, \"w\") as f:\n",
    "                json.dump(self.data, f, indent=4)\n",
    "\n",
    "            print(\"✓ Added labels:\", labels)\n",
    "            print(\"  confidences :\", conf)\n",
    "\n",
    "        print(\"\\nAll entries processed successfully.\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------- usage example\n",
    "if __name__ == \"__main__\":\n",
    "    # Example initialization and execution\n",
    "    skill_def = pd.read_csv(\"resources/skill_definitions.csv\")  # Must contain \"Skill\" column\n",
    "    client = OpenAI(api_key=\"sk-REDACTED\")\n",
    "    \n",
    "    labeler = TextLabeler(\n",
    "        data_path=\"resources/bedrock_demo.json\",\n",
    "        skill_def=skill_def,\n",
    "        client=client,\n",
    "        model=\"gpt-4o-mini\",\n",
    "    )\n",
    "    \n",
    "    labeler.revise_metadata_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "delta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
